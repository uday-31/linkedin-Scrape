{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import warnings\n",
    "import csv\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "import pickle\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the data file if it doesn't exist\n",
    "def createFile():\n",
    "    try:\n",
    "        f = open(\"linkedinProfileData.csv\")\n",
    "    except IOError:\n",
    "        with open('linkedinProfileData.csv', 'w') as csvFile:\n",
    "            csvWriter = csv.writer(csvFile)\n",
    "            csvWriter.writerow([\"number\",\"name\",\"headline\",\"about\",\"role\",\"organization\",\"time\",\"location\",\"description\",\"education\",\"degree\",\"major\",\"grade\",\"time\",\"description\",\"licenses and certifications\",\"skills\",\"accomplishments\",'interests'])\n",
    "    else:\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to implement infinite scrolling and scrape results\n",
    "#Saves required data and returns a list with new names added\n",
    "def scrapeData(driver,url,number,nameList):\n",
    "    driver.get(url)\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    while True:\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(1)\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            random.seed()\n",
    "            rand = random.randint(1,2)\n",
    "            if rand==1:\n",
    "                driver.execute_script(\"window.scrollTo(0, 0);\")\n",
    "            try:\n",
    "                \n",
    "                element_present = EC.presence_of_element_located((By.XPATH, \"//h3[@class='pv-entity__position-group-pager pv-profile-section__list-item ember-view']\"))\n",
    "                WebDriverWait(driver, 5).until(element_present)\n",
    "            except:\n",
    "                pass\n",
    "            break\n",
    "        last_height = new_height\n",
    "    \n",
    "    try:\n",
    "        element = driver.find_element_by_css_selector('button[class*=\"pv-browsemap-section__show-cta artdeco-card__action artdeco-button artdeco-button--icon-right artdeco-button--2 artdeco-button--fluid artdeco-button--tertiary ember-view\"]')\n",
    "        driver.execute_script(\"arguments[0].click();\", element)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    try:\n",
    "        element = driver.find_element_by_css_selector('a[class*=\"lt-line-clamp__more\"]')\n",
    "        driver.execute_script(\"arguments[0].click();\", element)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    appendData=list()\n",
    "    appendData.append(number)\n",
    "   \n",
    "    name=soup.find_all(class_='inline t-24 t-black t-normal break-words',limit=1)\n",
    "    name=name[0].getText()\n",
    "    name=name.strip()\n",
    "    appendData.append(name)\n",
    "    \n",
    "    headline=soup.find_all(class_='mt1 t-18 t-black t-normal break-words',limit=1)\n",
    "    if not headline:\n",
    "        appendData.append(\"NA\")\n",
    "    else:\n",
    "        headline=headline[0].getText()\n",
    "        headline=headline.strip()\n",
    "        appendData.append(headline)\n",
    "        \n",
    "    abt=soup.find_all(class_='pv-about__summary-text mt4 t-14 ember-view')\n",
    "    if abt:\n",
    "        abtStr=abt[0].getText()\n",
    "        appendData.append(abtStr[:-13])\n",
    "    else:\n",
    "        appendData.append(\"NA\")\n",
    "    \n",
    "    educ=soup.find_all(class_='pv-entity__position-group-pager pv-profile-section__list-item ember-view')\n",
    "    roleList=[]\n",
    "    orgList=[]\n",
    "    descList=[]\n",
    "    timeList=[]\n",
    "    locList=[]\n",
    "    if not educ:\n",
    "        appendData.append(\"NA\")\n",
    "        appendData.append(\"NA\")\n",
    "        appendData.append(\"NA\")\n",
    "        appendData.append(\"NA\")\n",
    "        appendData.append(\"NA\")\n",
    "    else:\n",
    "        for item in educ:\n",
    "            role=item.find_all(class_='t-16 t-black t-bold')\n",
    "            role=role[0].getText()\n",
    "            if \"Company Name\" in role:\n",
    "                role=item.find_all(class_='t-14 t-black t-bold')\n",
    "                role=role[0].getText()\n",
    "                role=role.strip()\n",
    "                role=role[6:]\n",
    "                org=item.find_all(class_='t-16 t-black t-bold')\n",
    "                org=org[0].getText()\n",
    "                org=org.strip()\n",
    "                org=org[13:]\n",
    "            else:\n",
    "                org=item.find_all(class_='pv-entity__secondary-title t-14 t-black t-normal')\n",
    "                org=org[0].getText()\n",
    "                org=org.strip()\n",
    "            desc=item.find_all(class_=\"pv-entity__description t-14 t-black t-normal inline-show-more-text inline-show-more-text--is-collapsed ember-view\")\n",
    "            if desc:\n",
    "                desc=desc[0].getText()\n",
    "                desc=desc[2:]\n",
    "                desc=desc[:desc.index('\\n')]\n",
    "            else:\n",
    "                desc=\"NA\"\n",
    "            timeL=item.find_all(class_=\"pv-entity__date-range t-14 t-black--light t-normal\")\n",
    "            if timeL:\n",
    "                timeL=timeL[0].find_all('span')\n",
    "                timeL=timeL[1].getText()\n",
    "            else:\n",
    "                timeL=\"NA\"\n",
    "            location=item.find_all(class_='pv-entity__location t-14 t-black--light t-normal block',limit=1)\n",
    "            if location:\n",
    "                location=location[0].getText()\n",
    "                location=location.strip()\n",
    "                location=location[9:]\n",
    "            else:\n",
    "                location=\"NA\"    \n",
    "            timeList.append(timeL)\n",
    "            roleList.append(role)\n",
    "            orgList.append(org)\n",
    "            descList.append(desc)\n",
    "            locList.append(location)\n",
    "            \n",
    "        \n",
    "        roleStr=\"\"\n",
    "        for item in roleList:\n",
    "            roleStr=roleStr+str(item)+' | '\n",
    "        orgStr=\"\"\n",
    "        for item in orgList:\n",
    "            orgStr=orgStr+str(item)+' | '\n",
    "        descStr=\"\"\n",
    "        for item in descList:\n",
    "            descStr=descStr+str(item)+' | '\n",
    "        timeStr=\"\"\n",
    "        for item in timeList:\n",
    "            timeStr=timeStr+str(item)+' | '\n",
    "        locStr=\"\"\n",
    "        for item in locList:\n",
    "            locStr=locStr+str(item)+' | '\n",
    "        \n",
    "        appendData.append(roleStr)\n",
    "        appendData.append(orgStr)\n",
    "        appendData.append(timeStr)\n",
    "        appendData.append(locStr)\n",
    "        appendData.append(descStr)\n",
    "        \n",
    "    educ=soup.find_all(class_='pv-profile-section__list-item pv-education-entity pv-profile-section__card-item ember-view')\n",
    "    schoolList=[]\n",
    "    degreeList=[]\n",
    "    majorList=[]\n",
    "    GPAList=[]\n",
    "    timeList=[]\n",
    "    descList=[]\n",
    "    if not educ:\n",
    "        appendData.append(\"NA\")\n",
    "        appendData.append(\"NA\")\n",
    "        appendData.append(\"NA\")\n",
    "        appendData.append(\"NA\")\n",
    "        appendData.append(\"NA\")\n",
    "        appendData.append(\"NA\")\n",
    "    else:\n",
    "        for item in educ:\n",
    "            school=item.find_all(class_='pv-entity__school-name t-16 t-black t-bold',limit=1)\n",
    "            school=school[0].getText()\n",
    "            school=school.strip()\n",
    "            degree=item.find_all(class_='pv-entity__secondary-title pv-entity__degree-name t-14 t-black t-normal',limit=1)\n",
    "            if degree:\n",
    "                degree=degree[0].getText()\n",
    "                degree=degree.strip()\n",
    "                degree=degree[12:]\n",
    "            else:\n",
    "                degree='NA'\n",
    "            major=item.find_all(class_='pv-entity__secondary-title pv-entity__fos t-14 t-black t-normal')\n",
    "            if major:\n",
    "                major=major[0].getText()\n",
    "                major=major.strip()\n",
    "                major=major[15:]\n",
    "            else:\n",
    "                major=\"NA\"\n",
    "            GPA=item.find_all(class_='pv-entity__secondary-title pv-entity__grade t-14 t-black t-normal')\n",
    "            if GPA:\n",
    "                GPA=GPA[0].getText()\n",
    "                GPA=GPA.strip()\n",
    "                GPA=GPA[6:]\n",
    "            else:\n",
    "                GPA=\"NA\"\n",
    "            timeL=item.find_all(class_='pv-entity__dates t-14 t-black--light t-normal')\n",
    "            if timeL:\n",
    "                timeL=timeL[0].getText()\n",
    "                timeL=timeL.strip()\n",
    "                timeL=timeL[38:]\n",
    "            else:\n",
    "                timeL=\"NA\"\n",
    "            desc=item.find_all(class_='pv-entity__description t-14 t-normal mt4')\n",
    "            if desc:\n",
    "                desc=desc[0].getText()\n",
    "            else:\n",
    "                desc=\"NA\"\n",
    "            schoolList.append(school)\n",
    "            degreeList.append(degree)\n",
    "            majorList.append(major)\n",
    "            GPAList.append(GPA)\n",
    "            timeList.append(timeL)\n",
    "            descList.append(desc)\n",
    "            \n",
    "        schoolStr=\"\"\n",
    "        for item in schoolList:\n",
    "            schoolStr=schoolStr+str(item)+' | '\n",
    "        degreeStr=\"\"\n",
    "        for item in degreeList:\n",
    "            degreeStr=degreeStr+str(item)+' | '\n",
    "        majorStr=\"\"\n",
    "        for item in majorList:\n",
    "            majorStr=majorStr+str(item)+' | '\n",
    "        GPAStr=\"\"\n",
    "        for item in GPAList:\n",
    "            GPAStr=GPAStr+str(item)+' | '\n",
    "        timeStr=\"\"\n",
    "        for item in timeList:\n",
    "            timeStr=timeStr+str(item)+' | '\n",
    "        descStr=\"\"\n",
    "        for item in descList:\n",
    "            descStr=descStr+str(item)+' | '\n",
    "            \n",
    "        appendData.append(schoolStr)\n",
    "        appendData.append(degreeStr)\n",
    "        appendData.append(majorStr)\n",
    "        appendData.append(GPAStr)\n",
    "        appendData.append(timeStr)\n",
    "        appendData.append(descStr)\n",
    "        \n",
    "    licStr=\"\"\n",
    "    lic=soup.find_all(class_='pv-certifications__summary-info pv-entity__summary-info pv-entity__summary-info--background-section pv-certifications__summary-info--has-extra-details')\n",
    "    if not lic:\n",
    "        appendData.append(\"NA\")\n",
    "    else:\n",
    "        for item in lic:\n",
    "            item2=item.getText()\n",
    "            item2=item2.split('\\n')\n",
    "            for item3 in item2:\n",
    "                if item3 not in ['Issuing authority','\\n','Issued date and, if applicable, expiration date of the certification or license','Credential Identifier']:\n",
    "                    licStr=licStr+str(item3)+\" \"\n",
    "            licStr=licStr+\" | \"\n",
    "        appendData.append(licStr)\n",
    "\n",
    "    skills=soup.find_all(class_='pv-skill-category-entity__name-text t-16 t-black t-bold')\n",
    "    skillStr=\"\"\n",
    "    if not skills:\n",
    "        appendData.append(\"NA\")\n",
    "    else:\n",
    "        for item in skills:\n",
    "            item2=item.getText()\n",
    "            item2=item2.split('\\n')\n",
    "            for item3 in item2:\n",
    "                if item3 not in['\\n','',' ']:\n",
    "                    skillStr=skillStr+item3+\" | \"\n",
    "        appendData.append(skillStr)\n",
    "                \n",
    "    \n",
    "    accom=soup.find_all(class_='pv-accomplishments-block__content break-words')\n",
    "    accomL=\"\"\n",
    "    if not accom:\n",
    "        appendData.append(\"NA\")\n",
    "    else:\n",
    "        for item in accom:\n",
    "            item2=item.getText()\n",
    "            item2=item2.split('\\n')\n",
    "            for item3 in item2:\n",
    "                if item3 in ['Honors & Awards','Languages',\"Language\",'Test Scores','Test Score','Organization','Organizations','Project','Projects','Course','Courses']:\n",
    "                    accomL=accomL+\" | \"+item3+\": \"\n",
    "                else:\n",
    "                    if item3 not in ['\\n','',' ']:\n",
    "                        accomL=accomL+item3+\", \"\n",
    "\n",
    "        appendData.append(accomL)\n",
    "        \n",
    "    inter=soup.find_all(class_='pv-entity__summary-title-text')\n",
    "    interL=\"\"\n",
    "    if not inter:\n",
    "        appendData.append(\"NA\")\n",
    "    else:\n",
    "        for item in inter:\n",
    "            item2=item.getText()\n",
    "            interL=interL+item2+\" | \"\n",
    "            \n",
    "        appendData.append(interL)\n",
    "        \n",
    "    \n",
    "    with open('linkedinProfileData.csv', 'a') as csvFile:\n",
    "        csvWriter = csv.writer(csvFile)\n",
    "        csvWriter.writerow(appendData)\n",
    "    \n",
    "    #print(appendData)\n",
    "    nextName=soup.find_all('span',class_='name',limit=5)\n",
    "    nextLink=soup.find_all(class_=\"pv-browsemap-section__member ember-view\",limit=5)\n",
    "    if not nextLink:\n",
    "        nextLink=soup.find_all(class_='ember-view pv-pymk-section__member',limit=5)\n",
    "    #print(nextName,nextLink)\n",
    "    for i in range(len(nextName)):\n",
    "        nextName[i]=[nextName[i].getText(),\"https://www.linkedin.com\"+nextLink[i]['href']]\n",
    "    nextNameCopy=nextName.copy()\n",
    "    if len(nextName)==0:\n",
    "        nextNameCopy=\"NA\"\n",
    "    else:\n",
    "        for i in range(len(nextName)):\n",
    "            if nextName[i] in nameList:\n",
    "                nextNameCopy.remove(nextName[i])\n",
    "    return (nextNameCopy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#controls the running of the scraping loop\n",
    "def control(driver,start,number=1,req=100):\n",
    "    ind=number-1\n",
    "    nameList=start\n",
    "    while number<req:\n",
    "        store=scrapeData(driver,nameList[ind][1],number,nameList)\n",
    "        if store != \"NA\":\n",
    "            for item in store:\n",
    "                nameList.append(item)\n",
    "            with open('dump.data', 'wb') as filehandle:\n",
    "                # store the data as binary data stream\n",
    "                pickle.dump(nameList, filehandle)\n",
    "        ind+=1\n",
    "        number+=1\n",
    "        time.sleep(3)\n",
    "    driver.close()\n",
    "    driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#login credentials\n",
    "def login(start,email,passw,number=1,req=100):\n",
    "    options=Options()\n",
    "    driver = webdriver.Firefox(options=options ,executable_path='/usr/local/Cellar/geckodriver/0.26.0/bin/geckodriver')\n",
    "    #time.sleep(60)\n",
    "    driver.get('https://www.linkedin.com/uas/login')\n",
    "    driver.find_element_by_name('session_key').send_keys(email)\n",
    "    driver.find_element_by_name('session_password').send_keys(passw)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        driver.find_element_by_xpath(\"//button[@class='btn__primary--large from__button--floating mercado-button--primary']\").click()\n",
    "    except:\n",
    "        driver.find_element_by_xpath(\"//button[@class='btn__primary--large from__button--floating']\").click()\n",
    "    #time.sleep(30)\n",
    "    control(driver,start,number,req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initial run\n",
    "def initialRun(startURL,startName,email,passw,req):\n",
    "    createFile()\n",
    "    start=[[startName,startURL]]\n",
    "    login(start,email,passw,1,req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subsequent runs\n",
    "def subsequentRun(email,passw,number,req):\n",
    "    with open('dump.data', 'rb') as filehandle:\n",
    "    # read the data as binary data stream\n",
    "        nameList = pickle.load(filehandle)\n",
    "    #print(len(nameList))\n",
    "    login(nameList,email,passw,number,req)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
